{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhnN2O+17BHf4Xa6tFpoYY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveenkumark1/Extensive_Vision_and_AI_V.4/blob/master/Week3/pytorch101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUSeLXLSdYjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Pytorch 101\n",
        "# Pytorch is a machine leanring frame work that helps to build models for research prototyping and also for deployment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc62HnBGefwh",
        "colab_type": "text"
      },
      "source": [
        "## Pytorch - Dataframes\n",
        "#### In pytorch we have a data frame called Tensor - It is the generalisation of matrix and arrays to a higher dimension.\n",
        "\n",
        "#### Tensor is an entity with defined order or rank \n",
        "\n",
        "#### Scalar - 0 order tensor\n",
        "#### Vector - 1 order tensor \n",
        "#### Matrix - 2 order tensor\n",
        "#### Array  - 3 order tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LMyE9nbgxLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Tensor Basics \n",
        "## Import Libraries \n",
        "\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elt_E5UklqAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a978e9f-4833-4335-82b1-47736ddfafb4"
      },
      "source": [
        "torch.zeros(0)  ## 0 order with zeros "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a64nhLtl8NX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "086bee94-7309-437e-8f37-6bbb783f3a22"
      },
      "source": [
        "torch.zeros(1,2)  ## 1 Order "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPtkrHtMmHhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "792f6333-87d2-45e4-d931-a6bbde168d2e"
      },
      "source": [
        "torch.zeros(2,2) ## 2 order "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27BUDGgTmThq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "c2e5eb96-7b91-42f8-ef72-5fc6f1d96767"
      },
      "source": [
        "# Random 3 order tensor\n",
        "\n",
        "torch.rand(2,3,4)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.9246, 0.5666, 0.1529, 0.1573],\n",
              "         [0.1483, 0.2220, 0.3184, 0.4911],\n",
              "         [0.9950, 0.0849, 0.9451, 0.2813]],\n",
              "\n",
              "        [[0.5773, 0.7091, 0.1846, 0.9436],\n",
              "         [0.4185, 0.2142, 0.0644, 0.7990],\n",
              "         [0.9860, 0.4469, 0.3270, 0.8944]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek3DEL_OmhE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "ac40d927-b15b-49f3-f89b-5ce79c7d7a11"
      },
      "source": [
        "torch.rand(3,2,3,2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.4755, 0.0305],\n",
              "          [0.0178, 0.2448],\n",
              "          [0.8213, 0.5701]],\n",
              "\n",
              "         [[0.4596, 0.0204],\n",
              "          [0.4485, 0.9785],\n",
              "          [0.4091, 0.6603]]],\n",
              "\n",
              "\n",
              "        [[[0.8153, 0.4955],\n",
              "          [0.0783, 0.6684],\n",
              "          [0.8401, 0.2982]],\n",
              "\n",
              "         [[0.9336, 0.1923],\n",
              "          [0.0782, 0.3600],\n",
              "          [0.9161, 0.4198]]],\n",
              "\n",
              "\n",
              "        [[[0.2113, 0.6698],\n",
              "          [0.3734, 0.9797],\n",
              "          [0.4144, 0.1260]],\n",
              "\n",
              "         [[0.1198, 0.7603],\n",
              "          [0.1875, 0.5249],\n",
              "          [0.4612, 0.4999]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqzNcSRPu305",
        "colab_type": "text"
      },
      "source": [
        "REF : https://pytorch.org/docs/stable/torch.html#creation-ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQyPmE5au_wH",
        "colab_type": "text"
      },
      "source": [
        "##Question 1:\n",
        "How many dimensions are there in a tensor defined as below?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAeJeDkTwcdz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11b1b366-dd40-42a1-cccb-240609d3db07"
      },
      "source": [
        "torch.rand(1, 1, 1, 1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.4901]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR4ubO2ww4iE",
        "colab_type": "text"
      },
      "source": [
        "### Ans 1 - 4 Dimension\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJMIOy55vAv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "2df04407-9bc7-48dd-93da-3f044e9a2966"
      },
      "source": [
        "torch.rand(2, 3, 4, 5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.2809, 0.0589, 0.2802, 0.3283, 0.1656],\n",
              "          [0.8770, 0.3118, 0.0609, 0.0205, 0.0315],\n",
              "          [0.6705, 0.0496, 0.5112, 0.4011, 0.4807],\n",
              "          [0.7547, 0.1232, 0.1053, 0.6530, 0.9750]],\n",
              "\n",
              "         [[0.8573, 0.6804, 0.5242, 0.1741, 0.7901],\n",
              "          [0.3481, 0.5976, 0.9414, 0.5110, 0.9543],\n",
              "          [0.5414, 0.7634, 0.0377, 0.4755, 0.7286],\n",
              "          [0.7612, 0.2691, 0.5230, 0.7228, 0.9563]],\n",
              "\n",
              "         [[0.7695, 0.1393, 0.2879, 0.6849, 0.3703],\n",
              "          [0.1704, 0.8487, 0.4913, 0.8266, 0.4879],\n",
              "          [0.8447, 0.6075, 0.0170, 0.0835, 0.5554],\n",
              "          [0.8108, 0.7392, 0.8888, 0.1212, 0.9381]]],\n",
              "\n",
              "\n",
              "        [[[0.5166, 0.0961, 0.8086, 0.1711, 0.6006],\n",
              "          [0.8288, 0.3401, 0.3702, 0.4448, 0.3563],\n",
              "          [0.6395, 0.3523, 0.9667, 0.6396, 0.0347],\n",
              "          [0.0641, 0.8161, 0.9659, 0.8801, 0.4999]],\n",
              "\n",
              "         [[0.3060, 0.2240, 0.7740, 0.2979, 0.4222],\n",
              "          [0.9170, 0.8365, 0.5702, 0.5098, 0.6032],\n",
              "          [0.3264, 0.4792, 0.4367, 0.9069, 0.8510],\n",
              "          [0.7316, 0.4903, 0.3246, 0.1541, 0.4068]],\n",
              "\n",
              "         [[0.1030, 0.9161, 0.2820, 0.5462, 0.1347],\n",
              "          [0.1552, 0.7933, 0.7112, 0.6263, 0.9616],\n",
              "          [0.4715, 0.4981, 0.7579, 0.2479, 0.0164],\n",
              "          [0.1112, 0.1179, 0.9807, 0.2699, 0.9170]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4xUxMlvvxrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6273e034-d63d-4a78-a8ff-26e760c41109"
      },
      "source": [
        "torch.rand(2, 3, 4, 5).size()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maB53Qygvzbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f597f7a1-a0fd-4b97-e21e-f2103e06010e"
      },
      "source": [
        "torch.rand(2, 3, 4, 5).shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSJbpNqHYQKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63d1f8ee-9981-4656-e4c3-b2a5a9873850"
      },
      "source": [
        "torch.rand(1, 1, 1, 1).size()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1k7YpPtZGwA",
        "colab_type": "text"
      },
      "source": [
        "## Python / NumPy / Pytorch interoperability\n",
        "You can create tensors from python as well as numpy arrays. You can also convert torch tensors to numpy arrays. So, the interoperability between torch and numpy is pretty good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHnRTu5jZGWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b8db9a2f-51ab-4b89-9d7b-825389a6ec7e"
      },
      "source": [
        "# Simple Python List\n",
        "python_list = [1, 2]\n",
        "\n",
        "# Create a numpy array from python list\n",
        "numpy_array = np.array(python_list)\n",
        "\n",
        "# Create a torch Tensor from python list\n",
        "tensor_from_list = torch.tensor(python_list)\n",
        "\n",
        "# Create a torch Tensor from Numpy array\n",
        "tensor_from_array = torch.tensor(numpy_array)                                   ### No Memory copy\n",
        "\n",
        "# Another way to create a torch Tensor from Numpy array (share same storage)\n",
        "tensor_from_array_v2 = torch.from_numpy(numpy_array)                            ### Memory Copy\n",
        "\n",
        "# Convert torch tensor to numpy array\n",
        "array_from_tensor = tensor_from_array.numpy()\n",
        "\n",
        "print('List:   ', python_list)\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_list)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)\n",
        "print('Array:  ', array_from_tensor)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List:    [1, 2]\n",
            "Array:   [1 2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Array:   [1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLiZRhgVerle",
        "colab_type": "text"
      },
      "source": [
        "Difference between `torch.Tensor` and `torch.from_numpy`\n",
        "\n",
        "Pytorch aims to be an effective library for computations. What does it mean? It means that pytorch avoids memory copying if it can."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZKLjojBewpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7dcd7085-633d-4f4b-cc92-9a94b5d32ed5"
      },
      "source": [
        "numpy_array[0] = 10\n",
        "\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array:   [10  2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([10,  2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry-qvVXpfQtc",
        "colab_type": "text"
      },
      "source": [
        "## Question 2:\n",
        "\n",
        "Assume that we moved our complete (cats vs dogs) image dataset to numpy arrays. Then we use torch.from_numpy to convert these images to tensor. Then we apply a specific data augmentation strategy called \"CutOut\" which blocks a portion of the image directly on these tensors. What will happen to the accuracy of a model trained on this strategy compared to the one without this strategy? CutOut strategy is shown below:\n",
        "\n",
        "![alt text](https://)\n",
        "\n",
        "CutOut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCDgjV3-gJgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8c2ea3bb-c9a2-4c69-a086-2398a3ef1e4c"
      },
      "source": [
        "print(tensor_from_array_v2)\n",
        "tensor_from_array_v2[0]=tensor_from_array_v2[0]+1 ## Assume this is cut out\n",
        "tensor_from_array_v2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10,  2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11,  2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0kmwQhCgkbU",
        "colab_type": "text"
      },
      "source": [
        "### Ans 2 : The accuracy will reduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcMcYGoBjSg5",
        "colab_type": "text"
      },
      "source": [
        "##Question 3:\n",
        "\n",
        "Why do you think we are observing this behavior?\n",
        "\n",
        "We have two different ways to create tensor from its NumPy counterpart - one copies memory and another one shares the same underlying storage. It works in the opposite way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcT43TT9jVvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "272dfc29-c8b6-40a0-83be-b3b0e95e7aae"
      },
      "source": [
        "array_from_tensor = tensor_from_array.numpy()\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)\n",
        "\n",
        "tensor_from_array[0] = 11\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor:  tensor([1, 2])\n",
            "Array:  [1 2]\n",
            "Tensor:  tensor([11,  2])\n",
            "Array:  [11  2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxz3g7--kGVr",
        "colab_type": "text"
      },
      "source": [
        "## Data types\n",
        "\n",
        "The basic data type of all Deep Learning-related operations is float, but sometimes you may need something else. Pytorch support different number types for its tensors the same way NumPy does it - by specifying the data type on tensor creation or via casting. Ths full list of supported data types can be found here.\n",
        "\n",
        "https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-7p6sCvruEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "02516c80-8004-4eae-a0cf-911c223a22f5"
      },
      "source": [
        "tensor = torch.zeros(2, 2)\n",
        "print('Tensor with default type: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.float16)\n",
        "print('Tensor with 16-bit float: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.int16)\n",
        "print('Tensor with integers: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.bool)\n",
        "print('Tensor with boolean data: ', tensor)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor with default type:  tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "Tensor with 16-bit float:  tensor([[0., 0.],\n",
            "        [0., 0.]], dtype=torch.float16)\n",
            "Tensor with integers:  tensor([[0, 0],\n",
            "        [0, 0]], dtype=torch.int16)\n",
            "Tensor with boolean data:  tensor([[False, False],\n",
            "        [False, False]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5FETpG3treT",
        "colab_type": "text"
      },
      "source": [
        "## Question 4:\n",
        "We saw above that some times numpy and tensors share same storage and changing one changes the other. If we define a rank-2-tensor with ones (dtype of f16), and then convert it into a numpy data type using tensor.numpy() and store it in a variable called \"num\", and then we perform this operation num = num * 0.5, will the original tensor have 1.0s or 0.5s as its element values?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MDjOxj4tvfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c3c95599-669a-4359-bf12-8558e53834fb"
      },
      "source": [
        "tensor = torch.ones(2,2, dtype = torch.float16)\n",
        "num = tensor.numpy()\n",
        "print(num)\n",
        "num = num*0.5\n",
        "print(num)\n",
        "print(tensor)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[0.5 0.5]\n",
            " [0.5 0.5]]\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDXuYJfoulQN",
        "colab_type": "text"
      },
      "source": [
        "### Ans 4 : The original tensor will have 1.0 as values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CpqB_oqvUX2",
        "colab_type": "text"
      },
      "source": [
        "## Question 5:\n",
        "If the operation `num = num*5` is changed to `num[:] = num*5` will the original tensor have 1.0s or 0.5s as its element values?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q3cfkAgv3yB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "15e3085f-080e-4eef-a848-9df0fb0d7387"
      },
      "source": [
        "tensor = torch.ones(2,2, dtype = torch.float16)\n",
        "num = tensor.numpy()\n",
        "print(num)\n",
        "num[:]=num*0.5\n",
        "num"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5, 0.5],\n",
              "       [0.5, 0.5]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flyyqmOQwu9A",
        "colab_type": "text"
      },
      "source": [
        "#### Ans 5 : The tensor will have 0.5 as values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlDedSzxw-d8",
        "colab_type": "text"
      },
      "source": [
        "# Indexing\n",
        "\n",
        "Tensor provides access to its elements via the same `[]` operation as a regular python list or NumPy array. However, as you may recall from NumPy usage, the full power of math libraries is accessible only via vectorized operations, i.e. operations without explicit looping over all vector elements in python and using implicit optimized loops in C/C++/CUDA/Fortran/etc. available via special function calls. Pytorch employs the same paradigm and provides a wide range of vectorized operations. Let's take a look at some examples.\n",
        "\n",
        "Joining a list of tensors together with `torch.cat`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu2nqaRgxazo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "21a7d3e4-04d6-415b-bf95-de09001e640b"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "print(torch.cat((a, b), dim=0))   #Join row wise - Axis 0"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaGjDJDwxc3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "179db040-f3d9-48ac-f709-0b9a041c18b9"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "print(torch.cat((a, b), dim=1))   #Join column wise - Axis = 1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 1., 1.],\n",
            "        [0., 0., 1., 1.],\n",
            "        [0., 0., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "164s0_71xzh1",
        "colab_type": "text"
      },
      "source": [
        "## Question 6:\n",
        "\n",
        "Is the transpose of concatenated a & b tensor on dimension 1, same as the contatenated tensor of a & b on dimension 0?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULXHmj37yNEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0949d63e-b054-4da8-c976-3f005ce78b9d"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "\n",
        "print(torch.flatten(torch.t(torch.cat((a, b), dim=0))))\n",
        "print(torch.flatten(torch.t(torch.cat((a, b), dim=1))))\n",
        "\n",
        "torch.flatten(torch.t(torch.cat((a, b), dim=0)))==torch.flatten(torch.t(torch.cat((a, b), dim=1)))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
            "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True, False, False, False, False, False, False,  True,\n",
              "         True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CakaPSukz-81",
        "colab_type": "text"
      },
      "source": [
        "#### Ans 6 : Not the same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y3EsNp81Jcg",
        "colab_type": "text"
      },
      "source": [
        "#### Indexing with another tensor/array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjqeD1c41OE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "f8f4adea-9886-4be4-f5e7-3285e86e946f"
      },
      "source": [
        "a = torch.arange(start=0, end=10)\n",
        "indices = np.arange(0, 10) > 5\n",
        "print(a)\n",
        "\n",
        "print(\"---------------------\")\n",
        "print(indices)\n",
        "print(a[indices])\n",
        "\n",
        "indices = torch.arange(start=0, end=10) %5\n",
        "print(\"---------------------\")\n",
        "print(indices)\n",
        "print(a[indices])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "---------------------\n",
            "[False False False False False False  True  True  True  True]\n",
            "tensor([6, 7, 8, 9])\n",
            "---------------------\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBeWxxr024jG",
        "colab_type": "text"
      },
      "source": [
        "## Question 7:\n",
        "\n",
        "`a` is defined as `torch.arange(start=0, end=10)`. We will create` b` using the two operations as below. In both cases do we get the same value?\n",
        "\n",
        " \n",
        "\n",
        "1.   Indices variable created by the modulo operation on arange between 0 and 10. Then a new varialble `b` is created from `a` using the last 5 elements of indices.\n",
        "2.   Indices variable created by the modulo operation on arange betwenn 1 and 11. Then a new varialble `b` is created from `a` using the last 5 elements of indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgT_Ol53U9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d188af46-eebf-420d-e122-ae7c0978ed37"
      },
      "source": [
        "a = torch.arange(start=0,end=10)\n",
        "print(a)\n",
        "\n",
        "indices = torch.arange(start=0, end=10) % 5\n",
        "print(indices)\n",
        "\n",
        "b = a[-5:]\n",
        "print(b)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([5, 6, 7, 8, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbgyBs5CGzhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "13edac85-0cd0-442e-91e7-df2cb8252c84"
      },
      "source": [
        "a = torch.arange(start=1,end=11)\n",
        "print(a)\n",
        "\n",
        "indices = torch.arange(start=0, end=10) % 5\n",
        "print(indices)\n",
        "\n",
        "b = a[-5:]\n",
        "print(b)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([ 6,  7,  8,  9, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zzOtdzfGzSU",
        "colab_type": "text"
      },
      "source": [
        "### Ans 7 : Both of them are not same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XNy1330K-Kp",
        "colab_type": "text"
      },
      "source": [
        "##### What should we do if we have, say, rank-2-tensor and want to select only some rows?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzGZMaCnLBoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "b9fbd84d-3cf4-4b76-ce4f-681f4d83f6aa"
      },
      "source": [
        "# Create a list of tensor to select the specific rows\n",
        "\n",
        "tensor = torch.rand((5, 3))\n",
        "rows = torch.tensor([0, 2])\n",
        "rows = torch.tensor([0, 2,3,3,4])\n",
        "\n",
        "print(tensor)\n",
        "print('-------------')\n",
        "print(rows)\n",
        "tensor[rows]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1265, 0.4498, 0.4787],\n",
            "        [0.0136, 0.7387, 0.4931],\n",
            "        [0.2969, 0.2384, 0.2163],\n",
            "        [0.9595, 0.5952, 0.9447],\n",
            "        [0.9267, 0.7557, 0.3961]])\n",
            "-------------\n",
            "tensor([0, 2, 3, 3, 4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1265, 0.4498, 0.4787],\n",
              "        [0.2969, 0.2384, 0.2163],\n",
              "        [0.9595, 0.5952, 0.9447],\n",
              "        [0.9595, 0.5952, 0.9447],\n",
              "        [0.9267, 0.7557, 0.3961]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaOhKYJiOeIa",
        "colab_type": "text"
      },
      "source": [
        "## Question 8:\n",
        "Consider a tensor defined as `torch.rand((6, 5))`. Is the shape of the new tensor created by taking the 0th, 2nd and 4th row of the old tensor same as the shape of the a newer tensor created by taking the 0th, 2nd and 4th row of the old tensor after transposing it by operation `torch.transpose(tensor, 0, 1)` ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuMPu-rzOyPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "584ef8a7-7751-4860-f130-79a56c0349ce"
      },
      "source": [
        "tensor = torch.rand((6,5))\n",
        "print(tensor)\n",
        "rows = torch.tensor([0,2,4])\n",
        "print(\"###########\")\n",
        "print(tensor[rows])\n",
        "print(\"------------------------\")\n",
        "tensor2 = torch.transpose(tensor,0,1)\n",
        "print(tensor2)\n",
        "rows = torch.tensor([0,2,4])\n",
        "print(\"###########\")\n",
        "print(tensor2[rows])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9549, 0.5885, 0.9858, 0.5392, 0.3323],\n",
            "        [0.3376, 0.4234, 0.2986, 0.7523, 0.9653],\n",
            "        [0.3708, 0.9787, 0.4402, 0.9136, 0.8287],\n",
            "        [0.9687, 0.1038, 0.2302, 0.2169, 0.5657],\n",
            "        [0.7379, 0.0106, 0.5198, 0.7596, 0.7252],\n",
            "        [0.0305, 0.0580, 0.3643, 0.4918, 0.3540]])\n",
            "###########\n",
            "tensor([[0.9549, 0.5885, 0.9858, 0.5392, 0.3323],\n",
            "        [0.3708, 0.9787, 0.4402, 0.9136, 0.8287],\n",
            "        [0.7379, 0.0106, 0.5198, 0.7596, 0.7252]])\n",
            "------------------------\n",
            "tensor([[0.9549, 0.3376, 0.3708, 0.9687, 0.7379, 0.0305],\n",
            "        [0.5885, 0.4234, 0.9787, 0.1038, 0.0106, 0.0580],\n",
            "        [0.9858, 0.2986, 0.4402, 0.2302, 0.5198, 0.3643],\n",
            "        [0.5392, 0.7523, 0.9136, 0.2169, 0.7596, 0.4918],\n",
            "        [0.3323, 0.9653, 0.8287, 0.5657, 0.7252, 0.3540]])\n",
            "###########\n",
            "tensor([[0.9549, 0.3376, 0.3708, 0.9687, 0.7379, 0.0305],\n",
            "        [0.9858, 0.2986, 0.4402, 0.2302, 0.5198, 0.3643],\n",
            "        [0.3323, 0.9653, 0.8287, 0.5657, 0.7252, 0.3540]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gXROISzPqik",
        "colab_type": "text"
      },
      "source": [
        "#### Ans 8 : Both are not same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTXYenwStTc",
        "colab_type": "text"
      },
      "source": [
        "## Tensor Shapes\n",
        "Reshaping a tensor is a frequently used operation. We can change the shape of a tensor without the memory copying overhead. There are two methods for that: `reshape` and `view`.\n",
        "\n",
        "The difference is the following:\n",
        "\n",
        "view tries to return a tensor, and it shares the same memory with the original tensor. In case, if it cannot reuse the same memory due to some reason, it just fails.\n",
        "reshape always returns the tensor with the desired shape and tries to reuse the memory. If it cannot, it creates a copy\n",
        "Let's see with the help of an example:\n",
        "\n",
        "https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj4fwueZXcO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "942c0be2-2bba-40aa-f72f-a061ebcdc688"
      },
      "source": [
        "tensor = torch.rand(2, 3, 4)\n",
        "print('Pointer to data: ', tensor.data_ptr())\n",
        "print('Shape: ', tensor.shape)\n",
        "print(\"---------------------------------------1\")\n",
        "\n",
        "reshaped = tensor.reshape(24)\n",
        "print(reshaped)\n",
        "print(\"---------------------------------------2\")\n",
        "view = tensor.view(3, 2, 4)\n",
        "print('Reshaped tensor - pointer to data', reshaped.data_ptr())\n",
        "print('Reshaped tensor shape ', reshaped.shape)\n",
        "print(\"---------------------------------------3\")\n",
        "print(view)\n",
        "print('Viewed tensor - pointer to data', view.data_ptr())\n",
        "print('Viewed tensor shape ', view.shape)\n",
        "print(\"---------------------------------------4\")\n",
        "\n",
        "assert tensor.data_ptr() == view.data_ptr()                                ### From here check below\n",
        "\n",
        "assert np.all(np.equal(tensor.numpy().flat, reshaped.numpy().flat))\n",
        "print('Original stride: ', tensor.stride())\n",
        "print('Reshaped stride: ', reshaped.stride())\n",
        "print('Viewed stride: ', view.stride())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pointer to data:  97588224\n",
            "Shape:  torch.Size([2, 3, 4])\n",
            "---------------------------------------1\n",
            "tensor([0.4045, 0.1032, 0.6344, 0.2552, 0.9201, 0.5120, 0.5860, 0.0792, 0.9513,\n",
            "        0.4800, 0.7331, 0.8075, 0.5813, 0.3268, 0.4761, 0.5862, 0.7244, 0.6576,\n",
            "        0.1768, 0.4067, 0.2196, 0.1905, 0.0503, 0.3988])\n",
            "---------------------------------------2\n",
            "Reshaped tensor - pointer to data 97588224\n",
            "Reshaped tensor shape  torch.Size([24])\n",
            "---------------------------------------3\n",
            "tensor([[[0.4045, 0.1032, 0.6344, 0.2552],\n",
            "         [0.9201, 0.5120, 0.5860, 0.0792]],\n",
            "\n",
            "        [[0.9513, 0.4800, 0.7331, 0.8075],\n",
            "         [0.5813, 0.3268, 0.4761, 0.5862]],\n",
            "\n",
            "        [[0.7244, 0.6576, 0.1768, 0.4067],\n",
            "         [0.2196, 0.1905, 0.0503, 0.3988]]])\n",
            "Viewed tensor - pointer to data 97588224\n",
            "Viewed tensor shape  torch.Size([3, 2, 4])\n",
            "---------------------------------------4\n",
            "Original stride:  (12, 4, 1)\n",
            "Reshaped stride:  (1,)\n",
            "Viewed stride:  (8, 4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClaSSdnPrJnQ",
        "colab_type": "text"
      },
      "source": [
        "The basic rule about reshaping the tensor is definitely that you cannot change the total number of elements in it, so the product of all tensor's dimensions should always be the same. It gives us the ability to avoid specifying one dimension when reshaping the tensor - Pytorch can calculate it for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZH_X_v0rL7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cae97fc5-d4e8-4f0f-e8f0-2fa513807357"
      },
      "source": [
        "print(tensor.reshape(3, 2, 4).shape)\n",
        "print(tensor.reshape(3, 2, -1).shape)\n",
        "print(tensor.reshape(3, -1, 4).shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jxnFpOErjt0",
        "colab_type": "text"
      },
      "source": [
        "## Question 9:\n",
        "\n",
        "Consider a tensor `a` created with `[1, 2, 3]` and `[1, 2, 3]` of size (2, 3) is reshaped with operation `.reshape(-1, 2)`. Also consider a tensor `b` created with [[2, 1]] and of size (1, 2), later operated with `view(2, -1)` operation.\n",
        "\n",
        "If we do a dot product of a and b (using `torch.mm`) and perform the sum of all the elements (using `torch.sum`) what do we get? (enter int value without any decimal point in the quiz)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjB1hCaUtVRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "bc0478cf-5812-4362-f504-f517cf476458"
      },
      "source": [
        "a = torch.tensor([[1,2,3],[1,2,3]])\n",
        "print(a)\n",
        "print(\"------------ 1\")\n",
        "print(a.reshape(-1,2))\n",
        "print(\"------------ 2\")\n",
        "b = torch.tensor([[2,1]])\n",
        "print(b.view(2,-1))\n",
        "print(\"------------ 3\")\n",
        "torch.sum(torch.mm(a.reshape(-1,2),b.view(2,-1)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "------------ 1\n",
            "tensor([[1, 2],\n",
            "        [3, 1],\n",
            "        [2, 3]])\n",
            "------------ 2\n",
            "tensor([[2],\n",
            "        [1]])\n",
            "------------ 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUjcUpOYwjd1",
        "colab_type": "text"
      },
      "source": [
        "#### Ans 9 - 18\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDszjzTHwoUX",
        "colab_type": "text"
      },
      "source": [
        "### Alternative ways to view tensors - `expand` or `expand_as`.\n",
        "\n",
        "`expand` - requires the desired shape as an input\n",
        "`expand_as` - uses the shape of another tensor\n",
        "These operations \"repeat\" tensor's values along the specified axes without actually copying the data.\n",
        "\n",
        "### As the documentation says, expand:\n",
        "\n",
        "returns a new view of the self tensor with singleton dimensions expanded to a larger size. Tensor can be also expanded to a larger number of dimensions, and the new ones will be appended at the front. For the new dimensions, the size cannot be set to -1.\n",
        "\n",
        "### Use case:\n",
        "\n",
        "index multi-channel tensor with single-channel mask - imagine a color image with 3 channels (RGB) and binary mask for the area of interest on that image. We cannot index the image with this kind of mask directly since the dimensions are different, but we can use `expand_as` operation to create a view of the mask that has the same dimensions as the image we want to apply it to, but has not copied the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Cw0Nzw1n5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "2d25bdd9-e4e5-43a3-cd22-ccf5f207c3bc"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Create a black image\n",
        "image = torch.zeros(size=(3, 256, 256), dtype=torch.int)\n",
        "\n",
        "# Leave the borders and make the rest of the image Green\n",
        "image[1, 18:256 - 18, 18:256 - 18] = 255\n",
        "\n",
        "# Create a mask of the same size\n",
        "mask = torch.zeros(size=(256, 256), dtype=torch.bool)\n",
        "\n",
        "# Assuming the green region in the original image is the Region of interest, change the mask to white for that area\n",
        "mask[18:256 - 18, 18:256 - 18] = 1\n",
        "\n",
        "# Create a view of the mask with the same dimensions as the original image\n",
        "mask_expanded = mask.expand_as(image)\n",
        "print(mask_expanded.shape)\n",
        "\n",
        "mask_np = mask_expanded.numpy().transpose(1, 2, 0) * 255\n",
        "image_np = image.numpy().transpose(1, 2, 0)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[0, mask] += 128\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[mask_expanded] += 128\n",
        "image.clamp_(0, 255)\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 256, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAMUklEQVR4nO3dT4yc9X3H8fenEDg0kYCiWpaxCo18\ncS8OtRBSoooe2hBfTC6IHIIVITkHkBKpPTjpIXtMKyWVkFokR0EYKYUiJRE+0D/UisQJghtRY6DA\nNgHZlrFVURGqSEkh3x72cTIhu+zO7szOzHffL+nRPPOb59nn99v9zkfP8+wzz6SqkCT18juz7oAk\nafIMd0lqyHCXpIYMd0lqyHCXpIYMd0lqaGrhnuTOJK8mWU5ybFrbkbaTda1FkWlc557kKuA14M+A\n88DzwOeq6uWJb0zaJta1Fsm09txvA5ar6sdV9QvgceDwlLYlbRfrWgtjWuG+Bzg38vz80CYtMuta\nC+PqWW04yVHg6PD0j2fVD+0MVZXt2pa1re20Vm1PK9wvAHtHnt80tI126DhwHCCJN7jRIli3rsHa\n1nyY1mmZ54F9SW5Jcg1wD3ByStuStot1rYUxlT33qnovyQPAvwBXAQ9X1UvT2Ja0XaxrLZKpXAo5\ndic8dNWUbec591HWtqZtrdr2E6qS1JDhLkkNGe6S1JDhLkkNGe6S1NDMPqG6WVVLs+6C5kSyNOsu\nTNQ8XLmm+ZBs/eIu99wlqSHDXZIaMtwlqSHDXZIaMtwlqSHDXZIaMtwlqSHDXZIaMtwlqSHDXZIa\nMtwlqSHDXZIaMtwlqSHDXZIaMtwlqaEt3c89yRvAu8D7wHtVdTDJDcA/AjcDbwB3V9X/bK2b0vay\ntrXoJrHn/qdVdaCqDg7PjwGnqmofcGp4Li0ia1sLaxqnZQ4DJ4b5E8BdU9iGNAvWthbGVsO9gH9N\n8u9Jjg5tu6rq4jD/FrBri9uQZsHa1kLb6neofqqqLiT5feDpJP85+mJVVZJVvxhyeMMcXe01aQ5Y\n21poW9pzr6oLw+Nl4PvAbcClJLsBhsfLa6x7vKoOjpzPlOaGta1Ft+lwT/K7ST52ZR74c+AscBI4\nMix2BHhyq52UtpO1rQ62clpmF/D9JFd+zj9U1T8neR54Isl9wJvA3VvvprStrG0tvFStetpwezux\nxrnL1VQtTbEnWiTJ0oaXrapMrydrG6+2Z/9e1HwYdiw2ZK3a9hOqktSQ4S5JDRnuktSQ4S5JDRnu\nktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ\n4S5JDRnuktSQ4S5JDRnuktTQuuGe5OEkl5OcHWm7IcnTSV4fHq8f2pPkwSTLSc4kuXWanZe2wtpW\nZxvZc38EuPMDbceAU1W1Dzg1PAf4DLBvmI4CD02mm9JUPIK1rabWDfeqegZ4+wPNh4ETw/wJ4K6R\n9kdrxbPAdUl2T6qz0iRZ2+pss+fcd1XVxWH+LWDXML8HODey3Pmh7bckOZrkdJLTm+yDNA3Wtlq4\neqs/oKoqSW1ivePAcYDNrC9Nm7WtRbbZPfdLVw5Jh8fLQ/sFYO/IcjcNbdKisLbVwmbD/SRwZJg/\nAjw50n7vcGXB7cA7I4e40iKwttXCuqdlkjwG3AHcmOQ88DXg68ATSe4D3gTuHhZ/CjgELAM/A74w\nhT5LE2Ftq7NUzf6U4DjnJauWptgTLZJkacPLVlWm15O1jVfbs38vaj4kGy/XtWrbT6hKUkOGuyQ1\nZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhL\nUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1tG64J3k4yeUkZ0falpJcSPLCMB0aee0rSZaTvJrk09Pq\nuLRV1rY628ie+yPAnau0/21VHRimpwCS7AfuAf5oWOfvk1w1qc5KE/YI1raaWjfcq+oZ4O0N/rzD\nwONV9fOq+gmwDNy2hf5JU2Ntq7OtnHN/IMmZ4dD2+qFtD3BuZJnzQ5u0SKxtLbzNhvtDwMeBA8BF\n4Bvj/oAkR5OcTnJ6k32QpsHaVgubCvequlRV71fVL4Fv8evD0wvA3pFFbxraVvsZx6vqYFUd3Ewf\npGmwttXFpsI9ye6Rp58FrlxtcBK4J8m1SW4B9gE/3FoXpe1jbauLq9dbIMljwB3AjUnOA18D7khy\nACjgDeCLAFX1UpIngJeB94D7q+r96XRd2hprW52lqmbdB5JsuBNVS1PsiRZJsrThZasq0+vJ2sar\n7dm/FzUfko2X61q17SdUJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12S\nGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJamhdcM9yd4k\nP0jycpKXknxpaL8hydNJXh8erx/ak+TBJMtJziS5ddqDkDbD2lZnG9lzfw/4i6raD9wO3J9kP3AM\nOFVV+4BTw3OAzwD7huko8NDEey1NhrWtttYN96q6WFU/GubfBV4B9gCHgRPDYieAu4b5w8CjteJZ\n4Lokuyfec2mLrG11NtY59yQ3A58AngN2VdXF4aW3gF3D/B7g3Mhq54c2aW5Z2+rm6o0umOSjwHeB\nL1fVT5P86rWqqiQ1zoaTHGXl0FaaKWtbHW1ozz3JR1gp/u9U1feG5ktXDkmHx8tD+wVg78jqNw1t\nv6GqjlfVwao6uNnOS1tlbaurjVwtE+DbwCtV9c2Rl04CR4b5I8CTI+33DlcW3A68M3KIK80Na1ud\nbeS0zCeBzwMvJnlhaPsq8HXgiST3AW8Cdw+vPQUcApaBnwFfmGiPpcmxttVWqsY6nTidToxxTrNq\naYo90SJJlja8bFVl/aUmb7zanv17UfNh9P8+61mrtv2EqiQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhL\nUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1tHDfxCRt\nxiJ8E5O0GX4TkyTtIIa7JDVkuEtSQ+uGe5K9SX6Q5OUkLyX50tC+lORCkheG6dDIOl9Jspzk1SSf\nnuYApM2yttVaVX3oBOwGbh3mPwa8BuwHloC/XGX5/cB/ANcCtwD/BVy1zjbKyWmak7Xt1HVaq/bW\n3XOvqotV9aNh/l3gFWDPh6xyGHi8qn5eVT8BloHb1tuOtN2sbXU21jn3JDcDnwCeG5oeSHImycNJ\nrh/a9gDnRlY7z4e/YaSZs7bVzYbDPclHge8CX66qnwIPAR8HDgAXgW+Ms+EkR5OcTnJ6nPWkSbO2\n1dGGwj3JR1gp/u9U1fcAqupSVb1fVb8EvsWvD08vAHtHVr9paPsNVXW8qg5W1cGtDEDaCmtbXW3k\napkA3wZeqapvjrTvHlnss8DZYf4kcE+Sa5PcAuwDfji5LkuTYW2rs6s3sMwngc8DLyZ5YWj7KvC5\nJAdY+Y/tG8AXAarqpSRPAC8D7wH3V9X762zjf4FXx+/+wroR+O9Zd2KbzMNY/2CNdmt78ubh771d\n5mGsa9X23Nxb5vROOoTdSePdSWNdzU4b/04a77yP1U+oSlJDhrskNTQv4X581h3YZjtpvDtprKvZ\naePfSeOd67HOxTl3SdJkzcueuyRpgmYe7knuHO6wt5zk2Kz7MwnDR9YvJzk70nZDkqeTvD48Xj+0\nJ8mDw/jPJLl1dj0f34fcWbHleMfRrbat6wUb73p3hZzmBFzFyp31/hC4hpU77u2fZZ8mNK4/AW4F\nzo60/Q1wbJg/Bvz1MH8I+CcgwO3Ac7Pu/5hjXevOii3HO8bvpV1tW9eLVdez3nO/DViuqh9X1S+A\nx1m5895Cq6pngLc/0HwYODHMnwDuGml/tFY8C1z3gU9IzrVa+86KLcc7hna1bV0vVl3POtx30l32\ndlXVxWH+LWDXMN/md/CBOyu2H+86dso42/+dF7WuZx3uO1KtHMe1ukxplTsr/krH8eq3dfw7L3Jd\nzzrcN3SXvSYuXTlMGx4vD+0L/ztY7c6KNB7vBu2Ucbb9Oy96Xc863J8H9iW5Jck1wD2s3Hmvo5PA\nkWH+CPDkSPu9w3/bbwfeGTnsm3tr3VmRpuMdw06p7ZZ/5xZ1Pev/6LLyX+bXWLmy4K9m3Z8Jjekx\nVr7k4f9YOfd2H/B7wCngdeDfgBuGZQP83TD+F4GDs+7/mGP9FCuHpmeAF4bpUNfxjvm7aVXb1vVi\n1bWfUJWkhmZ9WkaSNAWGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ19P+7j6Byp5s0HwAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}