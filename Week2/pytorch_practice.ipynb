{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyiQ6SlU6X7yETU1YyTM3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveenkumark1/Extensive_Vision_and_AI_V.4/blob/master/Week2/pytorch_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7X8JznTOrFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch                                      ## Import torch\n",
        "import torchvision                                ## Import torch vision for vision related data usage\n",
        "from torchvision import transforms, datasets      ## Import from torch vision importing ransforms and data sets for our use "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lrnt3__O9mb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "9767806b-2b1d-4965-92bc-678a7fecfd59"
      },
      "source": [
        "## Getting the data \n",
        "# Trianing Data  : MNIST 28 X 28\n",
        "\n",
        "train =  datasets.MNIST(\"\",train= True, download= True, transform = transforms.Compose([transforms.ToTensor()]))\n",
        "# variable = datasets.MNIST(\"\" = keep data in local,\n",
        "            # train = Consider the data as a trinaing set \n",
        "            # download = Download the data fromt the internet and keep in local\n",
        "            # transform = Data is not natively in the form of TENSOR, So to convert in to tensor we use this, \n",
        "            # transform the PIL format image to a transformed verison ) # Same is avaiable in documentaiton \n",
        "\n",
        "\n",
        "# Insample data & out sample data !! -> data for training and dat afor testing \n",
        "\n",
        "# Testing data \n",
        "\n",
        "test = datasets.MNIST(\"\",train= False, download= True, transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 19644406.83it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 208845.22it/s]           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5172596.19it/s]                           \n",
            "8192it [00:00, 65032.40it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg_7SO2SUrof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will extract the data that is downloaded in to the train by using the \" torch.util.dataloader \"\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle= True)\n",
        "\n",
        "# trainset = torch.utils.data.DDDDataLLLLoader(source, batch size , shuffle )\n",
        "\n",
        "# source = From where the data to be loaded \n",
        "# batch_size = How many of the items we need to pass through in one time to the network\n",
        "# shuffle = Generalisaiton (We feed data randomly so that the network can recognise the digits without any bias)\n",
        "\n",
        "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_9igw9TXAwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "903e88cd-85da-4fbc-ac59-00c4b7e72ecb"
      },
      "source": [
        "## Itereate over the data\n",
        "\n",
        "for data in trainset:\n",
        "  print(data)\n",
        "  break\n",
        "\n",
        "# This data will have a tensor of tensors - Images  and also tensor of tensors that are labels "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([6, 1, 6, 9, 9, 3, 3, 0, 5, 2])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xopai3pzgb6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "2ad966a1-973a-4182-b576-4b25fcc44b0a"
      },
      "source": [
        "data[0]  ## Images "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEbvetMVjo_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eb9e18b-2675-4e26-f752-2bb568268ed0"
      },
      "source": [
        "data[1]  # Labels"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 1, 6, 9, 9, 3, 3, 0, 5, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWw99c5Cjuht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = data[0][0], data[1][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHTGpEpWj3X4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01987d71-343c-46e0-9860-aa5ba70065f6"
      },
      "source": [
        "x"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.6392, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.1608, 0.9529, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.5176, 0.9922, 0.8784, 0.0784, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.4824, 0.9922, 0.9882, 0.4784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6784,\n",
              "          0.9922, 0.9961, 0.9922, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824, 0.9922,\n",
              "          0.9882, 0.9922, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.9137, 0.9961,\n",
              "          0.9922, 0.7961, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9137, 0.9882, 0.9922,\n",
              "          0.8314, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0431, 0.6784, 0.9961, 0.9922, 0.6392,\n",
              "          0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.3608, 0.9882, 0.9922, 0.9882, 0.0784,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0824, 0.8392, 0.9922, 0.9961, 0.5137, 0.2000,\n",
              "          0.3608, 0.5176, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.4000, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.9922, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.7961, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961,\n",
              "          0.8353, 0.9961, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.1608, 0.9529, 0.9922, 0.9882, 0.9922, 0.9882, 0.3569,\n",
              "          0.2000, 0.9922, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.4431, 0.9922, 0.9961, 0.9922, 0.9569, 0.1569, 0.0000,\n",
              "          0.4000, 0.9961, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.5961, 0.9882, 0.9922, 0.9882, 0.3176, 0.0000, 0.4824,\n",
              "          0.8745, 0.9922, 0.8314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.6000, 0.9922, 1.0000, 0.9922, 0.6000, 0.9137, 1.0000,\n",
              "          0.9922, 0.7176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.5961, 0.9882, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.7176, 1.0000, 0.9922, 1.0000, 0.9922, 0.8784,\n",
              "          0.3176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0784, 0.8353, 0.9882, 0.9137, 0.5922, 0.0784,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JstJioOLj5mZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ce6a634-1e84-418c-b749-e303d32b145b"
      },
      "source": [
        "y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPxXUzZhj-kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Printing the images to know if we are correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sETuqBwAkBxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "21aa80fb-7d9c-4a38-c57d-5e225e1c73b0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(data[0][0])\n",
        "\n",
        "# Shape mismatch (1,28,28) - Normal format is 28X28 - pytorch format 1X28X28"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7b7cd0da1ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Shape mismatch (1,28,28) - Normal format is 28X28 - pytorch format 1X28X28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2677\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 28, 28) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4TjLRZPlf-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "797a5b0b-6188-4d07-c1c8-925a3f2ff404"
      },
      "source": [
        "print(data[0][0].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnsRPvI9lDhu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbcc11a8-c53b-453f-dfac-d780e0d415a2"
      },
      "source": [
        "print(data[0][0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.6392, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.1608, 0.9529, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.5176, 0.9922, 0.8784, 0.0784, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.4824, 0.9922, 0.9882, 0.4784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6784,\n",
            "          0.9922, 0.9961, 0.9922, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824, 0.9922,\n",
            "          0.9882, 0.9922, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.9137, 0.9961,\n",
            "          0.9922, 0.7961, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9137, 0.9882, 0.9922,\n",
            "          0.8314, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0431, 0.6784, 0.9961, 0.9922, 0.6392,\n",
            "          0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.3608, 0.9882, 0.9922, 0.9882, 0.0784,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0824, 0.8392, 0.9922, 0.9961, 0.5137, 0.2000,\n",
            "          0.3608, 0.5176, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.4000, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
            "          0.9882, 0.9922, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.7961, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961,\n",
            "          0.8353, 0.9961, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.1608, 0.9529, 0.9922, 0.9882, 0.9922, 0.9882, 0.3569,\n",
            "          0.2000, 0.9922, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.4431, 0.9922, 0.9961, 0.9922, 0.9569, 0.1569, 0.0000,\n",
            "          0.4000, 0.9961, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.5961, 0.9882, 0.9922, 0.9882, 0.3176, 0.0000, 0.4824,\n",
            "          0.8745, 0.9922, 0.8314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.6000, 0.9922, 1.0000, 0.9922, 0.6000, 0.9137, 1.0000,\n",
            "          0.9922, 0.7176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.5961, 0.9882, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
            "          0.9882, 0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.7176, 1.0000, 0.9922, 1.0000, 0.9922, 0.8784,\n",
            "          0.3176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0784, 0.8353, 0.9882, 0.9137, 0.5922, 0.0784,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Jykr6nlwjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "955fb340-7463-4736-b619-0013b42b585e"
      },
      "source": [
        "## View function in pytorch \"\" view(28,28) \"\"\n",
        "\n",
        "print(data[0][0].shape)\n",
        "plt.imshow(data[0][0].view(28,28))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f954c2afd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkARhB5Ig7EAShB1I4v8BEp0K2xtauQQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIjo5KuLmjxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Balancing \n",
        "\n",
        "## Find the count of the every number in MNIST and also the percentage "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf20WbLw2ThU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "341502b3-001d-4f11-f9ff-5e4888132ffd"
      },
      "source": [
        "total = 0 \n",
        "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
        "\n",
        "for data in trainset:\n",
        "  xs, ys = data\n",
        "  for y in ys:\n",
        "    counter_dict[int(y)] += 1\n",
        "    total+=1\n",
        "    \n",
        "print(counter_dict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX5hwwYF4JOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "eadbf49e-8787-4db1-c0ff-729bd2829664"
      },
      "source": [
        "for i in counter_dict:\n",
        "  print(i,counter_dict[i]/total*100)\n",
        "\n",
        "  # Looks balanced !!"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 9.871666666666666\n",
            "1 11.236666666666666\n",
            "2 9.93\n",
            "3 10.218333333333334\n",
            "4 9.736666666666666\n",
            "5 9.035\n",
            "6 9.863333333333333\n",
            "7 10.441666666666666\n",
            "8 9.751666666666667\n",
            "9 9.915000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V9Cfe5V4hRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Lets build the Neural network and see !!\n",
        "\n",
        "import torch.nn as nn  \n",
        "import torch.nn.functional as F  ## This has the activaion functions\n",
        "\n",
        " ## torch.nn is more or object oriented programming and torch.functional is basically functions to run a single function \n",
        "\n",
        " ## Functions - Pass parameter\n",
        " ## NN - Initialise things "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsLS4yCN7TGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7c7c2bd2-39cd-4bc7-95fc-0b4785d6a14c"
      },
      "source": [
        "## Just a Network \n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):  ## Intialise the module Self\n",
        "    super().__init__() ## Initialisation to inherit the methods and (attributes?) from the parent class  -- Explore OOP  -- Super init error\n",
        "    ## Defining the fully connected layer \n",
        "\n",
        "    self.fc1 = nn.Linear(in_features= 28*28, out_features= 64, bias= True) \n",
        "   # planning to get 3 layers of 64 neurons in a layer - > output  \n",
        "   # self.fc1 = nn.Linear(FEATURES TO INPUT -> size of the image - flattened 28*28 or 784), FEATURES COMES IN OUTPUT -> 64 in this case, bias= EXPLORE)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 64)\n",
        "    self.fc4 = nn.Linear(64, 10)  # Note : Output is 10 - Because in MNIST the total output we have 10 classes\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSbYaLuJM65g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "674f2cbf-d403-40f2-fbfb-6da247fcb909"
      },
      "source": [
        "## We have defined a Neural network above, But we do not have the path for the data to pass through the network\n",
        "## We will define a feed forward neural network here - The info passes in only one direction \n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):  ## Intialise the module Self\n",
        "    super().__init__() ## Initialisation to inherit the methods and (attributes?) from the parent class  -- Explore OOP  -- Super init error\n",
        "    ## Defining the fully connected layer \n",
        "\n",
        "    self.fc1 = nn.Linear(in_features= 28*28, out_features= 64, bias= True) \n",
        "   # planning to get 3 layers of 64 neurons in a layer - > output  \n",
        "   # self.fc1 = nn.Linear(FEATURES TO INPUT -> size of the image - flattened 28*28 or 784), FEATURES COMES IN OUTPUT -> 64 in this case, bias= EXPLORE)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 64)\n",
        "    self.fc4 = nn.Linear(64, 10)  # Note : Output is 10 - Because in MNIST the total output we have 10 classes\n",
        "\n",
        "### FEED FORWARD NETWORK \n",
        "\n",
        "  def forward(self,x): ## Define a forward path for 'self' with input 'x'\n",
        "    x = self.fc1(x)  # Sending the data 'x' to fc1 and similarly through all others.\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    return(x)\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "### THIS NETWORK WILL NOT LEARN ANYTHING : The activaiton function is missing \n",
        "# Below we will write a network with the activation function also. "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k6kE_gOO1Zd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7c5ea731-900a-4cc0-efb1-b42a25ff5624"
      },
      "source": [
        "## NETWORK WITH ACTIVATION FUNCTION\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):  ## Intialise the module Self\n",
        "    super().__init__() ## Initialisation to inherit the methods and (attributes?) from the parent class  -- Explore OOP  -- Super init error\n",
        "    ## Defining the fully connected layer \n",
        "\n",
        "    self.fc1 = nn.Linear(in_features= 28*28, out_features= 64, bias= True) \n",
        "   # planning to get 3 layers of 64 neurons in a layer - > output  \n",
        "   # self.fc1 = nn.Linear(FEATURES TO INPUT -> size of the image - flattened 28*28 or 784), FEATURES COMES IN OUTPUT -> 64 in this case, bias= EXPLORE)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 64)\n",
        "    self.fc4 = nn.Linear(64, 10)  # Note : Output is 10 - Because in MNIST the total output we have 10 classes\n",
        "\n",
        "### FEED FORWARD NETWORK \n",
        "\n",
        "  def forward(self,x): ## Define a forward path for 'self' with input 'x'\n",
        "    x = F.relu(self.fc1(x))  \n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)               ### NO Activaiton funciton on the last  - Here we want only one class to be fired which gives the output. \n",
        "\n",
        "    ## To get a log probability distribution we will use 'softmax' as an optimizer in the last layer \n",
        "    return F.log_softmax(x, dim = 1)  ## We want the probability of all the classes to sum to one.- EXPLORE\n",
        "\n",
        "net = Net()\n",
        "print(net)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPNv1nHLQo_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.rand((28,28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCtzDWVCQw7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d313fe7-3920-4e6a-ba10-0d6621b9752a"
      },
      "source": [
        "X"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0432, 0.8029, 0.4199, 0.3051, 0.4970, 0.7194, 0.2392, 0.5460, 0.2554,\n",
              "         0.6509, 0.1950, 0.4137, 0.9747, 0.8669, 0.9475, 0.0373, 0.9008, 0.2262,\n",
              "         0.4915, 0.1807, 0.1808, 0.7964, 0.5285, 0.8059, 0.7987, 0.7394, 0.5325,\n",
              "         0.6151],\n",
              "        [0.8642, 0.8586, 0.9624, 0.1783, 0.1420, 0.6852, 0.5048, 0.3523, 0.7853,\n",
              "         0.2210, 0.7363, 0.2357, 0.0563, 0.0307, 0.3187, 0.7128, 0.0643, 0.1079,\n",
              "         0.8355, 0.3220, 0.4210, 0.4929, 0.5519, 0.9785, 0.5598, 0.9184, 0.2162,\n",
              "         0.3331],\n",
              "        [0.4838, 0.5260, 0.3764, 0.4150, 0.0155, 0.6126, 0.4997, 0.7241, 0.2187,\n",
              "         0.6892, 0.4101, 0.3262, 0.9455, 0.7299, 0.1924, 0.9353, 0.6861, 0.9679,\n",
              "         0.3508, 0.4930, 0.4584, 0.7365, 0.0185, 0.9124, 0.5522, 0.5546, 0.6310,\n",
              "         0.1896],\n",
              "        [0.7872, 0.0039, 0.0275, 0.6553, 0.4533, 0.1848, 0.8742, 0.2266, 0.9449,\n",
              "         0.1169, 0.9130, 0.3776, 0.6812, 0.4652, 0.3144, 0.8977, 0.2296, 0.9773,\n",
              "         0.7545, 0.7217, 0.1959, 0.0853, 0.6571, 0.4620, 0.8061, 0.3306, 0.2659,\n",
              "         0.5190],\n",
              "        [0.2929, 0.0414, 0.6671, 0.2934, 0.0801, 0.7078, 0.1217, 0.0359, 0.5745,\n",
              "         0.7152, 0.4960, 0.8808, 0.3653, 0.2503, 0.0763, 0.9751, 0.9430, 0.1841,\n",
              "         0.8766, 0.6696, 0.9026, 0.9062, 0.2343, 0.6872, 0.0971, 0.9453, 0.8342,\n",
              "         0.6083],\n",
              "        [0.0463, 0.9995, 0.1544, 0.7760, 0.1126, 0.2078, 0.8296, 0.1182, 0.5271,\n",
              "         0.5628, 0.5166, 0.5858, 0.5243, 0.7817, 0.7326, 0.5332, 0.1855, 0.4236,\n",
              "         0.2751, 0.1992, 0.5657, 0.5053, 0.6987, 0.7172, 0.1548, 0.5298, 0.1276,\n",
              "         0.1099],\n",
              "        [0.0160, 0.7766, 0.6824, 0.0650, 0.4860, 0.8123, 0.3304, 0.5317, 0.7355,\n",
              "         0.8721, 0.1362, 0.3547, 0.8660, 0.6462, 0.8499, 0.5114, 0.5139, 0.1338,\n",
              "         0.4569, 0.5234, 0.9568, 0.4480, 0.4317, 0.7424, 0.9227, 0.3866, 0.8223,\n",
              "         0.3846],\n",
              "        [0.0425, 0.6353, 0.9177, 0.5791, 0.3724, 0.0017, 0.7834, 0.4856, 0.6565,\n",
              "         0.0327, 0.1809, 0.6553, 0.8109, 0.3187, 0.2601, 0.2158, 0.1960, 0.1170,\n",
              "         0.9511, 0.1851, 0.7576, 0.9664, 0.3845, 0.1258, 0.3815, 0.8812, 0.6024,\n",
              "         0.6555],\n",
              "        [0.5080, 0.9178, 0.1136, 0.6641, 0.9965, 0.3933, 0.6166, 0.4521, 0.9730,\n",
              "         0.0201, 0.2936, 0.4243, 0.1529, 0.9695, 0.3552, 0.8459, 0.2591, 0.4714,\n",
              "         0.6356, 0.7583, 0.1795, 0.1823, 0.6610, 0.9981, 0.3438, 0.7464, 0.0382,\n",
              "         0.8598],\n",
              "        [0.1189, 0.0183, 0.1268, 0.6105, 0.9080, 0.6305, 0.8179, 0.0516, 0.1082,\n",
              "         0.1575, 0.8153, 0.9801, 0.8257, 0.4097, 0.8455, 0.6037, 0.3509, 0.4745,\n",
              "         0.0120, 0.5419, 0.3330, 0.7671, 0.9586, 0.9250, 0.4520, 0.5752, 0.8377,\n",
              "         0.4816],\n",
              "        [0.3808, 0.8544, 0.3400, 0.8069, 0.0671, 0.1406, 0.4887, 0.3237, 0.3766,\n",
              "         0.5860, 0.6258, 0.2593, 0.1083, 0.3882, 0.1916, 0.9061, 0.2924, 0.4730,\n",
              "         0.8027, 0.5220, 0.7146, 0.5591, 0.1288, 0.3463, 0.2909, 0.5914, 0.8437,\n",
              "         0.1480],\n",
              "        [0.5619, 0.5373, 0.6188, 0.2093, 0.2766, 0.6955, 0.5651, 0.3507, 0.2827,\n",
              "         0.7614, 0.0928, 0.7245, 0.0325, 0.1298, 0.6011, 0.0262, 0.2383, 0.6088,\n",
              "         0.8614, 0.8501, 0.9608, 0.2775, 0.0181, 0.6122, 0.5693, 0.7761, 0.7956,\n",
              "         0.9861],\n",
              "        [0.0820, 0.6694, 0.0869, 0.9056, 0.3933, 0.5504, 0.9334, 0.7564, 0.9565,\n",
              "         0.1092, 0.5761, 0.7273, 0.3381, 0.3681, 0.8594, 0.7456, 0.8387, 0.1812,\n",
              "         0.6575, 0.1723, 0.0688, 0.9390, 0.0970, 0.9672, 0.6135, 0.5829, 0.8827,\n",
              "         0.5522],\n",
              "        [0.4684, 0.7891, 0.9609, 0.6685, 0.5403, 0.3083, 0.6520, 0.0137, 0.6124,\n",
              "         0.1639, 0.6724, 0.2260, 0.8555, 0.0334, 0.4509, 0.5027, 0.6411, 0.1629,\n",
              "         0.7419, 0.0689, 0.5666, 0.5467, 0.6373, 0.2906, 0.2307, 0.8721, 0.4961,\n",
              "         0.3599],\n",
              "        [0.7316, 0.5153, 0.0822, 0.0586, 0.1622, 0.4014, 0.9461, 0.0284, 0.6139,\n",
              "         0.2393, 0.3199, 0.9354, 0.4534, 0.7957, 0.5378, 0.6742, 0.4581, 0.1155,\n",
              "         0.2403, 0.2921, 0.4539, 0.0981, 0.0073, 0.3424, 0.0693, 0.8247, 0.7327,\n",
              "         0.2408],\n",
              "        [0.2107, 0.1276, 0.3992, 0.8847, 0.3951, 0.0541, 0.2214, 0.2655, 0.5375,\n",
              "         0.3994, 0.6388, 0.2365, 0.4441, 0.1916, 0.5852, 0.9425, 0.3026, 0.5840,\n",
              "         0.1182, 0.3047, 0.4081, 0.3346, 0.3915, 0.0547, 0.8682, 0.5813, 0.1976,\n",
              "         0.3347],\n",
              "        [0.9858, 0.2150, 0.6538, 0.4130, 0.0687, 0.3446, 0.1434, 0.7821, 0.2506,\n",
              "         0.8938, 0.8615, 0.5825, 0.4448, 0.1498, 0.9569, 0.6164, 0.5503, 0.0487,\n",
              "         0.3018, 0.8458, 0.9305, 0.4515, 0.0055, 0.0128, 0.9744, 0.4834, 0.8296,\n",
              "         0.8955],\n",
              "        [0.9503, 0.7081, 0.6750, 0.5386, 0.8981, 0.3506, 0.7464, 0.5486, 0.8213,\n",
              "         0.4547, 0.1728, 0.9753, 0.3457, 0.0247, 0.7113, 0.4566, 0.6653, 0.0235,\n",
              "         0.3583, 0.8151, 0.1848, 0.9360, 0.5135, 0.4903, 0.3747, 0.5623, 0.3069,\n",
              "         0.8922],\n",
              "        [0.8829, 0.2086, 0.0039, 0.2599, 0.2673, 0.2750, 0.8617, 0.9388, 0.6642,\n",
              "         0.0804, 0.0640, 0.0373, 0.8058, 0.5315, 0.7248, 0.8597, 0.8478, 0.6352,\n",
              "         0.5623, 0.2478, 0.7213, 0.9830, 0.2140, 0.9882, 0.9850, 0.6592, 0.3217,\n",
              "         0.8395],\n",
              "        [0.8934, 0.2340, 0.4886, 0.3436, 0.8907, 0.4712, 0.4523, 0.8205, 0.3625,\n",
              "         0.3268, 0.9380, 0.6433, 0.7660, 0.0869, 0.5582, 0.6381, 0.4762, 0.1070,\n",
              "         0.6257, 0.6759, 0.2640, 0.8847, 0.4480, 0.5964, 0.9175, 0.3492, 0.9287,\n",
              "         0.4819],\n",
              "        [0.5396, 0.2841, 0.0539, 0.1438, 0.1623, 0.8776, 0.4228, 0.2103, 0.1571,\n",
              "         0.1373, 0.6080, 0.2571, 0.8410, 0.8807, 0.1670, 0.2296, 0.2995, 0.8530,\n",
              "         0.2376, 0.3936, 0.4435, 0.0090, 0.6837, 0.1934, 0.3846, 0.7046, 0.1412,\n",
              "         0.6540],\n",
              "        [0.3414, 0.5879, 0.4240, 0.1369, 0.8486, 0.0638, 0.2187, 0.0750, 0.8681,\n",
              "         0.1006, 0.8919, 0.7119, 0.8170, 0.9035, 0.1260, 0.6784, 0.4551, 0.6051,\n",
              "         0.4060, 0.3143, 0.4285, 0.1188, 0.7340, 0.2010, 0.1427, 0.7878, 0.4463,\n",
              "         0.3937],\n",
              "        [0.3006, 0.0038, 0.7685, 0.1313, 0.8468, 0.4993, 0.3090, 0.1013, 0.8820,\n",
              "         0.1962, 0.0431, 0.7016, 0.0206, 0.8785, 0.1645, 0.6026, 0.7812, 0.4334,\n",
              "         0.1751, 0.7100, 0.7667, 0.3204, 0.5643, 0.2766, 0.8514, 0.2713, 0.2269,\n",
              "         0.9790],\n",
              "        [0.7850, 0.0745, 0.6314, 0.3035, 0.0783, 0.8345, 0.3302, 0.2085, 0.7431,\n",
              "         0.0751, 0.3609, 0.6906, 0.1239, 0.0551, 0.3486, 0.9721, 0.1363, 0.4533,\n",
              "         0.0155, 0.7473, 0.1283, 0.7463, 0.8460, 0.1277, 0.0375, 0.4771, 0.5552,\n",
              "         0.2797],\n",
              "        [0.0400, 0.4362, 0.4071, 0.9162, 0.3877, 0.9350, 0.3700, 0.6758, 0.1952,\n",
              "         0.9820, 0.6621, 0.2870, 0.6642, 0.7454, 0.3915, 0.1456, 0.9300, 0.6048,\n",
              "         0.6910, 0.0185, 0.3665, 0.0443, 0.1113, 0.9228, 0.2224, 0.5075, 0.1269,\n",
              "         0.3794],\n",
              "        [0.5433, 0.7925, 0.0560, 0.3581, 0.6762, 0.5591, 0.4498, 0.6041, 0.4316,\n",
              "         0.7920, 0.2695, 0.5664, 0.4291, 0.5749, 0.2031, 0.3684, 0.3683, 0.1838,\n",
              "         0.1013, 0.2472, 0.3590, 0.3477, 0.8281, 0.8339, 0.9774, 0.2290, 0.3861,\n",
              "         0.8629],\n",
              "        [0.0069, 0.8845, 0.3316, 0.5573, 0.0235, 0.9812, 0.3203, 0.8220, 0.8087,\n",
              "         0.0688, 0.3816, 0.8096, 0.9740, 0.2336, 0.7424, 0.1177, 0.1327, 0.8858,\n",
              "         0.9425, 0.9608, 0.7031, 0.8427, 0.3236, 0.4775, 0.9161, 0.9908, 0.5800,\n",
              "         0.7559],\n",
              "        [0.5568, 0.3175, 0.8833, 0.2120, 0.8997, 0.2555, 0.1260, 0.1547, 0.2730,\n",
              "         0.4080, 0.1116, 0.9317, 0.5462, 0.9235, 0.1317, 0.1732, 0.6736, 0.5903,\n",
              "         0.0807, 0.0936, 0.6288, 0.7617, 0.6396, 0.3191, 0.2172, 0.3159, 0.0142,\n",
              "         0.6077]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ednYk0xQ4l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "702a69ab-83a3-4ed0-e7f0-17dbec917cec"
      },
      "source": [
        "output = net(X)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-705efee85c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-cf37bdb14f1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## Define a forward path for 'self' with input 'x'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [28 x 28], m2: [784 x 64] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:197"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB2xlIMvRKUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a74dd26-0f94-4421-9fad-2a74631da4f6"
      },
      "source": [
        "X = X.view(-1, 28*28)   ## -1 is unknown shape , Be ready of any size of data. Same works for 1 also\n",
        "output = net(X)\n",
        "output"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.1718, -2.2231, -2.4441, -2.4715, -2.4042, -2.3169, -2.1750, -2.3070,\n",
              "         -2.3039, -2.2582]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ3P6F_tSG7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b69a85ee-e026-4bc8-a5b6-6808ecd89cdb"
      },
      "source": [
        "print(X.shape)\n",
        "plt.imshow(X.view(28,28))\n",
        "\n",
        "# Below is the image that we generated using the random data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 784])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f954c1e0748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUQHS5knTQrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## LETS PASS LABELED DATA AND MAKE THE MODEL RECOGNISE THE SAME : Pass hand written digits and make the network recognise : \n",
        "\n",
        "# We need to understand Loss and OPtimiser in this case\n",
        "\n",
        "# Loss : How wrong is the model ( How confident is the model in its prediction - It always has some percent of error )\n",
        "# Optimiser : Adjust the weights based on the loss and lower the loss ( works on the learning rate )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcZHFMbwxWXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfer leanring : Dont adjust weights in the beginning, Adjust weights only in the end parts of the network\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)  ## lr -> Learning rate - Decaying leaning rate - Explore !!\n",
        "\n",
        "EPOCHS = 3 ## How many times the data needs to pass in the network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_CU0DztzKX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a7419901-7234-429c-d95c-eebc9f781741"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  for data in trainset:\n",
        "    ## Data is a batch of features and labels\n",
        "    X,y = data  ## X -> grey scale pixel values     &      y -> lables of those pixel values \n",
        "    #print(X[0])\n",
        "    #print(y[0])\n",
        "    #break\n",
        "\n",
        "    net.zero_grad()                   # Forevery batch zero the gradient - EXPLORE !!\n",
        "    output = net(X.view(-1,28*28))    # Get the output of the network we built\n",
        "    loss = F.nll_loss(output,y)       # Compare the output of our network with the actual y\n",
        "\n",
        "    ## If data is NOT one hot vector ( if its a scalar value ) use nll_loss or if its one hot vector use MSE\n",
        "    loss.backward()                   # Backpropogate the loss \n",
        "    optimizer.step()\n",
        "  print(loss) \n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9378, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0025, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFRRzaZizKTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "494ff1c1-f46e-4225-fedc-3d7be52dd2bf"
      },
      "source": [
        "# Lets see how correct we were - We are not optimising the model we are just seeing how good the model is !\n",
        "\n",
        "correct = 0 \n",
        "total = 0 \n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in trainset:\n",
        "    X, y = data\n",
        "    output = net(X.view(-1,28*28))\n",
        "    for idx, i in enumerate(output):\n",
        "      if torch.argmax(i)==y[idx]:\n",
        "        correct +=1\n",
        "      total +=1\n",
        "\n",
        "print(\"Accuracy :\", round(correct/total,3))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6jpDHE6zKQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c258a155-d533-47b9-f810-02633a6452f3"
      },
      "source": [
        "# Lets check ut the images\n",
        "plt.imshow(X[0].view(28,28))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f95439f9128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l6Rd8DIzKN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ab566bb-ed92-4b9d-fa67-06aaed046d36"
      },
      "source": [
        "# Lets checkt he number\n",
        "y[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFWlc7gvzKK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbSnqUxozKBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}